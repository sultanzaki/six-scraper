name: Run Web Scraper

on:
  schedule:
    - cron: '*/15 * * * *'
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository and pull latest changes
      uses: actions/checkout@v2
      with:
        fetch-depth: 0  # Fetch all history
    
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install tweepy requests beautifulsoup4
    
    - name: Run scraper
      run: |
        python -V
        python scraper.py
      env:
        API_KEY: ${{ secrets.API_KEY }}
        API_SECRET_KEY: ${{ secrets.API_SECRET_KEY }}
        ACCESS_TOKEN: ${{ secrets.ACCESS_TOKEN }}
        ACCESS_TOKEN_SECRET: ${{ secrets.ACCESS_TOKEN_SECRET }}
        BEARER_TOKEN: ${{ secrets.BEARER_TOKEN }}
        COOKIES_KHONGGUAN: ${{ secrets.COOKIES_KHONGGUAN }}
    
    - name: Debug file content
      run: |
        echo "Content of last_grades.json:"
        cat last_grades.json
    
    - name: Commit and push if changes
      run: |
        git config --global user.name 'GitHub Action'
        git config --global user.email 'action@github.com'
        git add last_grades.json
        git diff --quiet && git diff --staged --quiet || (git commit -m "Update grades data" && git push origin main)
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
